{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d1b35b-0d9a-41ba-916c-6fec75d0c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v5: change hadcrut to C&W\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import iris\n",
    "import iris.quickplot as qplt\n",
    "import iris.plot as iplt\n",
    "from iris.experimental.regrid import regrid_weighted_curvilinear_to_rectilinear\n",
    "import json\n",
    "import cftime\n",
    "from itertools import product\n",
    "from cftime import DatetimeNoLeap\n",
    "import Utils.iris_utils\n",
    "import Utils.Gridding\n",
    "from Utils.nc_processing import *\n",
    "from Utils.analysis import * \n",
    "#from Utils.plotting import *\n",
    "import esmvalcore.preprocessor\n",
    "import xesmf as xe\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "#sns.set()\n",
    "\n",
    "def legend_without_duplicate_labels(ax):\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    unique = [(h, l) for i, (h, l) in enumerate(zip(handles, labels)) if l not in labels[:i]]\n",
    "    ax.legend(*zip(*unique))\n",
    "    \n",
    "\n",
    "def make_df(path):\n",
    "    all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "    df = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def get_baseline(df, t_bnds=[1850, 1900], monthly=False, multi_ens=False):\n",
    "    df_hist = df[df['Experiment']=='historical']\n",
    "    df_hist = df_hist[df_hist['year'] > t_bnds[0]][df_hist['year'] < t_bnds[1]]\n",
    "    df_hist['base_t_bnds'] = str(t_bnds[0]) + '-' + str(t_bnds[1])\n",
    "    if monthly:\n",
    "        df_hist = df_hist.groupby(['Model', 'base_t_bnds', 'Month']).mean().reset_index().rename(columns=baseline_name_changes)\n",
    "    else:\n",
    "        if multi_ens:\n",
    "            df_hist = df_hist.groupby(['Model', 'Ensemble_member', 'base_t_bnds']).mean().reset_index().rename(columns=baseline_name_changes)\n",
    "        else:\n",
    "            df_hist = df_hist.groupby(['Model', 'base_t_bnds']).mean().reset_index().rename(columns=baseline_name_changes)\n",
    "    df_hist = df_hist.drop(columns=['year'])\n",
    "    return df_hist\n",
    "\n",
    "def wmean(df, values, weights):\n",
    "    return sum(df[weights]*df[values])/df[weights].sum()\n",
    "\n",
    "def preprocess_hadcrut_z(df, window, preind_period=[1850,1900]):\n",
    "    \"\"\" hadcrut analysis annual means tas data is donwloaded as anomaly relative to the period \n",
    "        1961-1990, (see description here: https://www.metoffice.gov.uk/hadobs/hadcrut5/data/current/download.html)\n",
    "        we preprocess by re-baselining this to be anomaly relative to our preindustrial period, 1850-1900\"\"\n",
    "    \n",
    "    returns df with tas relative to pre-industrial mean \"\"\"\n",
    "    df.rename(columns={'Time':'Year'}, inplace=True)\n",
    "    df_pre_ind = df[df['Year'].between(preind_period[0], preind_period[1])]\n",
    "    offset = df_pre_ind['Anomaly (deg C)'].mean()\n",
    "    df_out = df[['Year', 'Anomaly (deg C)']]\n",
    "    df_out['Anomaly (deg C)'] = df_out['Anomaly (deg C)'] - offset\n",
    "    df_out['Anomaly (deg C)'] = df_out['Anomaly (deg C)'].rolling(window, center=True).mean()\n",
    "    return df_out\n",
    "\n",
    "def preprocess_obs(df, window, preind_period=[1850,1900]):\n",
    "    \"\"\" hadcrut analysis annual means tas data is donwloaded as anomaly relative to the period \n",
    "        1961-1990, (see description here: https://www.metoffice.gov.uk/hadobs/hadcrut5/data/current/download.html)\n",
    "        we preprocess by re-baselining this to be anomaly relative to our preindustrial period, 1850-1900\"\"\n",
    "    \n",
    "    returns df with tas relative to pre-industrial mean \"\"\"\n",
    "    #df.rename(columns={'Time':'Year'}, inplace=True)\n",
    "    df_pre_ind = df[df['year'].between(preind_period[0], preind_period[1])]\n",
    "    offset_w = df_pre_ind['world_tas'].mean()\n",
    "    offset_na = df_pre_ind['no_arctic_tas'].mean()\n",
    "    df_out = df.copy()\n",
    "    df_out['world_tas'] = df_out['world_tas'] - offset_w\n",
    "    df_out['no_arctic_tas'] = df_out['no_arctic_tas'] - offset_na\n",
    "    df_out['world_tas'] = df_out['world_tas'].rolling(window, center=True).mean()\n",
    "    df_out['no_arctic_tas'] = df_out['no_arctic_tas'].rolling(window, center=True).mean()\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304c9307-7082-494d-a881-f6b761194c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "### set up and read in temp data\n",
    "\n",
    "## models\n",
    "baseline_name_changes = {'no_arctic_tas':'no_arctic_base_tas',\n",
    "                         'world_tas':'world_base_tas',\n",
    "                        }\n",
    "window=10\n",
    "temp_thresh = 1.5\n",
    "#temp_thresh = 2\n",
    "\n",
    "in_folder_tas = 'int_outputs/temperature_v2/'\n",
    "#exp='ssp370'\n",
    "exp='ssp245'\n",
    "#exp='ssp126'\n",
    "tas_df = make_df(in_folder_tas)\n",
    "tas_df = tas_df[tas_df['Experiment'].isin(['historical', exp])]\n",
    "#tas_df.set_index('year',inplace=True)\n",
    "print(tas_df['Model'].unique())\n",
    "\n",
    "## observations\n",
    "#Hadcrut_file = 'Inputs/HadCRUT5/Downloaded_29_12_22/HadCRUT.5.0.1.0.analysis.summary_series.global.annual.csv'\n",
    "#Hadcrut_file = 'int_outputs/temperature_hadcrut/hadcrut5_tas.csv'\n",
    "CW_file = 'int_outputs/temperature_CW/CW_tas.csv'\n",
    "\n",
    "Obs_df = preprocess_obs(pd.read_csv(CW_file), window=window)\n",
    "obs_set = 'Cowtan & Way'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f3bab6-24cd-48b5-8727-fd0d2df66221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc45f240-29ea-4dec-92e1-9b46efb58c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "### initial processing, add baseline temp to each model, \n",
    "### only keep those models with a historic scenario available\n",
    "\n",
    "tas_df = tas_df.groupby(['year', 'Experiment', 'Model']).mean().reset_index() \n",
    "\n",
    "base_tas_df = get_baseline(tas_df, [1850, 1900])\n",
    "tas_df = pd.merge(tas_df, base_tas_df, how='left', on=['Model'])\n",
    "tas_df['no_arctic_tas_anom'] = tas_df['no_arctic_tas'] - tas_df['no_arctic_base_tas']\n",
    "tas_df['world_tas_anom'] = tas_df['world_tas'] - tas_df['world_base_tas']\n",
    "\n",
    "models = tas_df[tas_df['Experiment']==exp]['Model'].unique()\n",
    "tas_df = tas_df[tas_df['Model'].isin(models)]\n",
    "tas_df = tas_df.dropna()\n",
    "\n",
    "models = tas_df['Model'].unique()\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd41f2c8-c3e3-49d0-b1a1-9f5b87237944",
   "metadata": {},
   "outputs": [],
   "source": [
    "### initial basic plot, no correction to force realistic present temps\n",
    "\n",
    "for model in models:\n",
    "    df = tas_df[tas_df['Model']==model]\n",
    "    plt.plot(df['year'], df['world_tas_anom'].rolling(window, center=True).mean(), c='b', alpha=0.5, linewidth=0.5, label='Global')\n",
    "    plt.plot(df['year'], df['no_arctic_tas_anom'].rolling(window, center=True).mean(), c='r', alpha=0.5, linewidth=0.5, label='No arctic')\n",
    "\n",
    "df = tas_df.groupby(['year']).mean().reset_index() \n",
    "plt.plot(df['year'], df['world_tas_anom'].rolling(window, center=True).mean(), c='b', alpha=1, linewidth=2, label='Global')\n",
    "plt.plot(df['year'], df['no_arctic_tas_anom'].rolling(window, center=True).mean(), c='r', alpha=1, linewidth=2, label='No arctic')\n",
    "\n",
    "legend_without_duplicate_labels(plt.gca())\n",
    "plt.xlim(1980,2050)\n",
    "plt.axhline(1.5)\n",
    "plt.savefig('Figures/tas_anom_global_and_no_arctic.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed354c89-b6fe-439b-aee3-31b86bb8080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#df= tas_df[tas_df['Experiment'] == exp]\n",
    "df = tas_df.drop(columns=['Experiment'])\n",
    "models = df['Model'].unique()\n",
    "Model = []\n",
    "No_arctic = []\n",
    "World = []\n",
    "\n",
    "for m in models:\n",
    "    m_df = df[df['Model']==m]\n",
    "    no_arctic_crossing_year = np.interp(temp_thresh, m_df['no_arctic_tas_anom'].rolling(window, center=True).mean(), m_df['year'])\n",
    "    world_crossing_year = np.interp(temp_thresh, m_df['world_tas_anom'].rolling(window, center=True).mean(), m_df['year'])\n",
    "    Model.append(m)\n",
    "    No_arctic.append(np.round(no_arctic_crossing_year,3))\n",
    "    World.append(np.round(world_crossing_year,3))\n",
    "\n",
    "out_df = pd.DataFrame({'Model':Model,\n",
    "                       'No_arctic_crossing_year':No_arctic,\n",
    "                       'World_crossing_year':World})\n",
    "out_df['gap'] = out_df['No_arctic_crossing_year'] - out_df['World_crossing_year']\n",
    "print('mean gap for crossing {}C: '.format(temp_thresh) + str(np.round(out_df['gap'].mean(), 2)))\n",
    "#out_df.to_csv('Outputs/crossing_years.csv')\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4452987-7b24-4abb-a8ce-bf92d609618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bda9d9-04e8-4842-8ad1-6e6a3798236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" repeat, this time scaling temps to current observed warming \"\"\"\n",
    "\n",
    "global_warming_obs = float(Obs_df.dropna().tail(1)['world_tas'])\n",
    "no_arctic_warming_obs = float(Obs_df.dropna().tail(1)['no_arctic_tas'])\n",
    "\n",
    "obs_year = int(Obs_df.dropna().tail(1)['year'])\n",
    "\n",
    "Model = []\n",
    "No_arctic = []\n",
    "World = []\n",
    "df = tas_df\n",
    "M_df = pd.DataFrame(columns=df.columns)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    for m in models:\n",
    "        m_df = df[df['Model']==m]\n",
    "        m_df['rolling_world_anom'] = m_df['world_tas_anom'].rolling(window, center=True).mean()\n",
    "        m_df['rolling_no_arctic_anom'] = m_df['no_arctic_tas_anom'].rolling(window, center=True).mean()\n",
    "        \n",
    "        ratio_w = (m_df[m_df['year']==obs_year]['rolling_world_anom']/global_warming_obs).values[0]\n",
    "        ratio_na = (m_df[m_df['year']==obs_year]['rolling_no_arctic_anom']/no_arctic_warming_obs).values[0]\n",
    "        \n",
    "        m_df['adjusted_world_tas_anom']= (m_df['world_tas_anom']/ratio_w).rolling(window, center=True).mean()\n",
    "        m_df['adjusted_no_arctic_tas_anom']= (m_df['no_arctic_tas_anom']/ratio_na).rolling(window, center=True).mean()\n",
    "        \n",
    "        m_df_plot = m_df[m_df['year'] >= obs_year]\n",
    "        \n",
    "        plt.plot(m_df_plot['year'], m_df_plot['adjusted_world_tas_anom'],\n",
    "                 c='b', alpha=0.5, linewidth=0.5, label='CMIP6')\n",
    "        plt.plot(m_df_plot['year'], m_df_plot['adjusted_no_arctic_tas_anom'], \n",
    "                 c='r', alpha=0.5, linewidth=0.5, label='CMIP6 without AA')\n",
    "\n",
    "        M_df = M_df.append(m_df, ignore_index = True)\n",
    "        #also calc crossings again\n",
    "        no_arctic_crossing_year = np.interp(temp_thresh, m_df['adjusted_no_arctic_tas_anom'], m_df['year'])\n",
    "        world_crossing_year = np.interp(temp_thresh, m_df['adjusted_world_tas_anom'], m_df['year'])\n",
    "        Model.append(m)\n",
    "        No_arctic.append(np.round(no_arctic_crossing_year,3))\n",
    "        World.append(np.round(world_crossing_year,3))\n",
    "\n",
    "out_df = pd.DataFrame({'Model':Model,\n",
    "                       'No_arctic_crossing_year':No_arctic,\n",
    "                       'World_crossing_year':World})\n",
    "out_df['gap'] = out_df['No_arctic_crossing_year'] - out_df['World_crossing_year']\n",
    "\n",
    "#mm_mean_df = out_df.groupby()\n",
    "\n",
    "## add observations:\n",
    "plt.plot(Obs_df['year'], Obs_df['world_tas'], c='blue', \n",
    "         linestyle='--', label='{}'.format(obs_set))\n",
    "plt.plot(Obs_df['year'], Obs_df['no_arctic_tas'], c='red', \n",
    "         linestyle='--', label='{} without AA'.format(obs_set))\n",
    "\n",
    "legend_without_duplicate_labels(plt.gca())\n",
    "plt.xlim(2000,2065)\n",
    "plt.ylim(0.7, 2.7)\n",
    "plt.axhline(2, color='gray')\n",
    "plt.axhline(1.5, color='gray')\n",
    "plt.ylabel('TAS anomaly (°C)')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.savefig('Figures/tas_projections.png', dpi=300)\n",
    "\n",
    "print('observation year: ' + str(obs_year))\n",
    "print('{} temp in obs_year:'.format(obs_set) + str(global_warming_obs))\n",
    "print('{} temp without AA in obs_year:'.format(obs_set) + str(no_arctic_warming_obs))\n",
    "print('AA contrib:' + str((global_warming_obs-no_arctic_warming_obs)))\n",
    "print('AA contrib (%)' + str((global_warming_obs-no_arctic_warming_obs)/global_warming_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20521f0-659d-4960-aade-dca64da99f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep_m_df = ['year', 'Experiment', 'Model', 'adjusted_world_tas_anom', 'adjusted_no_arctic_tas_anom']\n",
    "M_df = M_df[cols_to_keep_m_df]\n",
    "\n",
    "M_df.to_csv('Outputs/master_df_temp_projections_{r}yr_rolling_{scenario}.csv'.format(r=window, scenario=exp))\n",
    "Obs_df.to_csv('Outputs/Processed_{o}_{r}yr_rolling.csv'.format(o=obs_set, r=window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b0d208-5af2-44bb-aabb-bebd08052106",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = str(np.round(out_df['gap'].mean(), 2))\n",
    "standard_error = str(np.round(out_df['gap'].sem(), 2))\n",
    "print('mean gap for crossing {}C: '.format(temp_thresh)+mean+' +- '+standard_error+' years')\n",
    "out_df.to_csv('Outputs/crossing_years_adjusted_{r}yr_rolling_{e}_{t}C_thresh.csv'.format(r=window, e=exp, t=temp_thresh))\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a89e6c-d79c-482c-b722-5b86d3437b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb476f84-bd06-431b-9053-e410b307e98c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ca7392-b71a-4a30-b64f-737b39060428",
   "metadata": {},
   "outputs": [],
   "source": [
    "### now generate box plot by model (vertical), with multiple ensemble members for error bars\n",
    "\n",
    "in_folder_tas = 'int_outputs/temperature_multi_ens/'\n",
    "\n",
    "tas_df = make_df(in_folder_tas)\n",
    "tas_df = tas_df[tas_df['Experiment'].isin(['historical', exp])]\n",
    "\n",
    "tas_df = tas_df.groupby(['year', 'Experiment', 'Model', 'Ensemble_member']).mean().reset_index() \n",
    "\n",
    "base_tas_df = get_baseline(tas_df, [1850, 1900], multi_ens=True)\n",
    "\n",
    "tas_df = pd.merge(tas_df, base_tas_df, how='left', on=['Model', 'Ensemble_member'])\n",
    "tas_df['no_arctic_tas_anom'] = tas_df['no_arctic_tas'] - tas_df['no_arctic_base_tas']\n",
    "tas_df['world_tas_anom'] = tas_df['world_tas'] - tas_df['world_base_tas']\n",
    "\n",
    "models = tas_df[tas_df['Experiment']==exp]['Model'].unique()\n",
    "tas_df = tas_df[tas_df['Model'].isin(models)]\n",
    "tas_df = tas_df.dropna()\n",
    "\n",
    "models = tas_df['Model'].unique()\n",
    "\n",
    "#tas_df = tas_df[tas_df['Experiment'] != 'historical']\n",
    "#tas_df = tas_df.drop(columns=['Experiment'])\n",
    "\n",
    "#also calc crossings\n",
    "Model = []\n",
    "Ensemble_member = []\n",
    "No_arctic = []\n",
    "World = []\n",
    "for m in models:\n",
    "    m_df = tas_df[tas_df['Model']==m]\n",
    "    ens_mems = m_df[m_df['Experiment']=='ssp245']['Ensemble_member'].unique()\n",
    "    #print(m)\n",
    "    for e in ens_mems:\n",
    "        #print(e)\n",
    "    \n",
    "        me_df = m_df[m_df['Ensemble_member']==e]\n",
    "        me_df.sort_values(by='year', axis=0)\n",
    "\n",
    "        me_df['rolling_world_anom'] = me_df['world_tas_anom'].rolling(window, center=True).mean()\n",
    "        me_df['rolling_no_arctic_anom'] = me_df['no_arctic_tas_anom'].rolling(window, center=True).mean()\n",
    "\n",
    "        try:\n",
    "            ratio_w = (me_df[me_df['year']==obs_year]['rolling_world_anom']/global_warming_obs).values[0]\n",
    "            ratio_na = (me_df[me_df['year']==obs_year]['rolling_no_arctic_anom']/no_arctic_warming_obs).values[0]\n",
    "        except:\n",
    "            print('error on: ' + m + e)\n",
    "            \n",
    "        me_df['adjusted_world_tas_anom']= (me_df['rolling_world_anom']/ratio_w)\n",
    "        me_df['adjusted_no_arctic_tas_anom']= (me_df['rolling_no_arctic_anom']/ratio_na)\n",
    "        \n",
    "        no_arctic_crossing_year = np.interp(temp_thresh, me_df['adjusted_no_arctic_tas_anom'], me_df['year'])\n",
    "        world_crossing_year = np.interp(temp_thresh, me_df['adjusted_world_tas_anom'], me_df['year'])\n",
    "        Model.append(m)\n",
    "        No_arctic.append(np.round(no_arctic_crossing_year,3))\n",
    "        World.append(np.round(world_crossing_year,3))\n",
    "        Ensemble_member.append(e)\n",
    "            \n",
    "\n",
    "out_df_ME = pd.DataFrame({'Model':Model,\n",
    "                          'Ensemble_member':Ensemble_member,\n",
    "                       'No_arctic_crossing_year':No_arctic,\n",
    "                       'World_crossing_year':World})\n",
    "out_df_ME['gap'] = out_df_ME['No_arctic_crossing_year'] - out_df_ME['World_crossing_year']\n",
    "\n",
    "out_df_ME_all = out_df_ME.copy()\n",
    "out_df_ME_all.to_csv('Outputs/Crossing_years_multi_ensemble_mems_{r}yr_rolling_{e}_{t}C_thresh.csv'.format(r=window, e=exp, t=temp_thresh))\n",
    "## keep only models with more than x ensemble members:\n",
    "ens_members_needed = 3\n",
    "models_to_keep = []\n",
    "for m in models:\n",
    "    n = len(out_df_ME[out_df_ME['Model']==m])\n",
    "    if n >= ens_members_needed:\n",
    "        models_to_keep.append(m)\n",
    "\n",
    "out_df_ME = out_df_ME[out_df_ME['Model'].isin(models_to_keep)]\n",
    "\n",
    "out_df_ME.to_csv('Outputs/Crossing_years_multi_ensemble_mems_for_box_plot_{r}yr_rolling_{e}_{t}C_thresh.csv'.format(r=window, e=exp, t=temp_thresh))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b71535-2f93-443a-aa50-21097dba28d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df_ME_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d7a8c1-8fdb-42bb-933c-dccc5200198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot\n",
    "sns.boxplot(data=out_df_ME, x='gap', y='Model', color='gray', showfliers = False)\n",
    "sns.stripplot(data=out_df_ME, x='gap', y='Model', color='black', marker='X')\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Years later crossing {}°C'.format(temp_thresh))\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.grid(color = 'green', linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(5, 8)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Figures/crossing_years.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28251e6-afc8-4f5c-9ef2-3508a5098a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcc429b-561f-43f2-b897-4be25045fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(out_df_ME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bcc63d-d45c-4c14-ac56-34128a9e29aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2765c5b9-3598-4b3a-8731-546740f418d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
